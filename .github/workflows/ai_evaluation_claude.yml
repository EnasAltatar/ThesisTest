name: AI Evaluation Pipeline - Claude

on:
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Run in test mode (first 5 notes only)'
        required: true
        type: boolean
        default: true

jobs:
  evaluate-notes:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install anthropic pandas openpyxl numpy
      
      - name: Verify input files
        run: |
          echo "Checking for required files..."
          echo "Current directory: $(pwd)"
          echo "Repository contents:"
          ls -la
          echo ""
          echo "Data directory contents:"
          ls -lh data/ || { echo "âŒ Error: data/ directory not found"; exit 1; }
          echo ""
          if [ ! -f "data/khcc_eval_input.xlsx" ]; then
            echo "âŒ Error: khcc_eval_input.xlsx not found in data/ directory"
            exit 1
          fi
          echo "âœ“ Input file found: data/khcc_eval_input.xlsx"
      
      - name: Configure evaluation mode
        run: |
          if [ "${{ inputs.test_mode }}" = "true" ]; then
            echo "ðŸ§ª Running in TEST MODE"
            sed -i 's/TEST_MODE = False/TEST_MODE = True/' scripts/ai_evaluator_claude.py
          else
            echo "ðŸš€ Running in FULL MODE"
            sed -i 's/TEST_MODE = True/TEST_MODE = False/' scripts/ai_evaluator_claude.py
          fi
      
      - name: Run AI evaluation
        env:
          ANTHROPIC_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
        run: |
          python scripts/ai_evaluator_claude.py
      
      - name: Upload evaluation results
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: ai-evaluation-results-${{ github.run_number }}
          path: |
            outputs/ai_evaluations.csv
            outputs/ai_evaluations_full.json
            outputs/ai_evaluations_summary.csv
          retention-days: 90
      
      - name: Create summary comment
        if: success()
        run: |
          echo "# AI Evaluation Complete! ðŸŽ‰" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Number:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Date:** $(date)" >> $GITHUB_STEP_SUMMARY
          echo "**Model:** Claude Haiku 4" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Download your results from the Artifacts section below." >> $GITHUB_STEP_SUMMARY
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "âŒ AI Evaluation Pipeline Failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the logs above for error details." >> $GITHUB_STEP_SUMMARY
