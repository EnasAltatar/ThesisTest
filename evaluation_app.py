import io
from datetime import datetime

import pandas as pd
import streamlit as st

st.set_page_config(
    page_title="Thesis Evaluation Tool ‚Äî KHCC (Blinded, 5 Notes)",
    layout="wide",
)

# -----------------------------
# Helpers
# -----------------------------
def normalise_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    Make column names predictable:
    - lower-case
    - strip spaces
    - map common variants -> case_id, note_label, note_text, note_source
    """
    col_map = {}
    for c in df.columns:
        key = c.strip().lower().replace(" ", "_")
        col_map[c] = key

    df = df.rename(columns=col_map)

    # Additional alias handling
    rename_extra = {}
    for c in df.columns:
        if c in ["case", "caseid", "case_id.1"]:
            rename_extra[c] = "case_id"
        if c in ["note", "note_body", "notecontent", "note_text.1"]:
            rename_extra[c] = "note_text"
        if c in ["label", "noteletter", "note_label.1"]:
            rename_extra[c] = "note_label"
        if c in ["source", "origin", "note_source.1"]:
            rename_extra[c] = "note_source"
    if rename_extra:
        df = df.rename(columns=rename_extra)

    # Make sure the critical columns exist
    required = {"case_id", "note_label", "note_text"}
    missing = required - set(df.columns)
    if missing:
        st.error(
            f"Uploaded file is missing required columns: {', '.join(sorted(missing))}.\n\n"
            "Expected at least: case_id, note_label, note_text."
        )
        st.stop()

    # Force case_id to string like "Case 1"
    df["case_id"] = df["case_id"].astype(str).str.strip()
    df["note_label"] = df["note_label"].astype(str).str.strip()
    return df


def init_state():
    if "eval_df" not in st.session_state:
        st.session_state.eval_df = pd.DataFrame()  # all scores


init_state()

# -----------------------------
# Sidebar: setup & file upload
# -----------------------------
st.sidebar.header("Setup")

evaluator_name = st.sidebar.text_input("Evaluator name*", value="", placeholder="Your name")
center = st.sidebar.text_input("Center / Dept", value="")

wizard_mode = st.sidebar.toggle("Wizard Mode (one question at a time)", value=False)

uploaded_file = st.sidebar.file_uploader(
    "Upload cases (khcc_eval_input.xlsx)",
    type=["xlsx", "xls"],
    help="Use the khcc_eval_input.xlsx generated by build_eval_input.py",
)

df_cases = None
if uploaded_file is not None:
    raw_df = pd.read_excel(uploaded_file)
    df_cases = normalise_columns(raw_df)
    st.sidebar.success(f"Loaded {len(df_cases)} rows.")
    with st.sidebar.expander("Preview columns", False):
        st.write(df_cases.head())
else:
    st.sidebar.info("Please upload khcc_eval_input.xlsx to start.")

# -----------------------------
# Top navigation (tabs)
# -----------------------------
tabs = st.tabs(["üè† Home", "üß™ Evaluate", "üìä Review", "üì§ Export"])

# -----------------------------
# HOME
# -----------------------------
with tabs[0]:
    st.title("Thesis Evaluation Tool ‚Äî KHCC (Blinded, 5 Notes)")
    st.markdown(
        """
This tool lets KHCC clinical pharmacists **blindly evaluate 5 different notes (A‚ÄìE) per case**.

**Important points:**
- Upload the prepared Excel file (`khcc_eval_input.xlsx`).
- Choose a *Case ID* and then a *Note label* (A, B, C, D, or E).
- Read the note and score it according to the rubric.
- Your scores are stored locally in the browser session and can be exported from the **Export** tab.
"""
    )

# -----------------------------
# EVALUATE
# -----------------------------
with tabs[1]:
    st.header("Evaluate a Case / Note")

    if df_cases is None or df_cases.empty:
        st.info("Upload `khcc_eval_input.xlsx` in the sidebar to start.")
    else:
        # ---- Case selection ----
        case_ids = sorted(df_cases["case_id"].unique(), key=lambda x: (len(x), x))
        selected_case = st.selectbox("Case ID", options=case_ids)

        case_df = df_cases[df_cases["case_id"] == selected_case]

        if case_df.empty:
            st.warning("No notes available for this case.")
        else:
            # ---- Note selection A‚ÄìE ----
            available_labels = sorted(case_df["note_label"].unique())
            selected_label = st.selectbox(
                "Note label",
                options=available_labels,
                format_func=lambda x: f"Note {x}",
            )

            note_row = case_df[case_df["note_label"] == selected_label].iloc[0]

            # ---- Layout: Note text + Instructions ----
            left, right = st.columns([2.2, 1.3])

            with left:
                st.subheader(f"Clinical Pharmacist Note ‚Äî {selected_label}")
                st.text_area(
                    "Note text",
                    value=str(note_row["note_text"]),
                    height=450,
                    disabled=True,
                )

            with right:
                st.subheader("Instructions")
                st.markdown(
                    """
Evaluate this note using the rubric below.  
Try to score **all notes (A‚ÄìE)** for this case before moving on.
                    """
                )

            st.markdown("---")

            # ---- Scoring form ----
            st.subheader("Evaluation")

            # A simple rubric ‚Äì you can adjust labels/ranges as needed
            if wizard_mode:
                # one question at a time
                q1 = st.slider(
                    "Clinical safety (0 = unsafe, 10 = very safe)",
                    0,
                    10,
                    5,
                )
                q2 = st.slider(
                    "Appropriateness of recommendations (0‚Äì10)",
                    0,
                    10,
                    5,
                )
                q3 = st.slider(
                    "Completeness of the note (0‚Äì10)",
                    0,
                    10,
                    5,
                )
                q4 = st.slider(
                    "Clarity & organization (0‚Äì10)",
                    0,
                    10,
                    5,
                )
                overall = st.slider(
                    "Overall impression (0‚Äì10)",
                    0,
                    10,
                    5,
                )
            else:
                cols = st.columns(5)
                q1 = cols[0].slider("Safety", 0, 10, 5)
                q2 = cols[1].slider("Appropriateness", 0, 10, 5)
                q3 = cols[2].slider("Completeness", 0, 10, 5)
                q4 = cols[3].slider("Clarity", 0, 10, 5)
                overall = cols[4].slider("Overall", 0, 10, 5)

            comments = st.text_area("Comments (optional)", height=120)

            if st.button("Save evaluation for this note"):
                if not evaluator_name:
                    st.error("Please enter your name in the sidebar before saving.")
                else:
                    row_dict = {
                        "timestamp": datetime.now().isoformat(timespec="seconds"),
                        "evaluator": evaluator_name,
                        "center": center,
                        "case_id": selected_case,
                        "note_label": selected_label,
                        "note_source": note_row.get("note_source", ""),
                        "safety": q1,
                        "appropriateness": q2,
                        "completeness": q3,
                        "clarity": q4,
                        "overall": overall,
                        "comments": comments,
                    }

                    # Append or create evaluation df
                    st.session_state.eval_df = pd.concat(
                        [st.session_state.eval_df, pd.DataFrame([row_dict])],
                        ignore_index=True,
                    )
                    st.success(
                        f"Saved evaluation for {selected_case}, Note {selected_label}."
                    )

# -----------------------------
# REVIEW
# -----------------------------
with tabs[2]:
    st.header("Review Your Evaluations")

    if st.session_state.eval_df.empty:
        st.info("No evaluations saved yet.")
    else:
        st.dataframe(st.session_state.eval_df, use_container_width=True)

        cases_done = (
            st.session_state.eval_df.groupby("case_id")["note_label"]
            .nunique()
            .reset_index()
        )
        st.subheader("Progress by case")
        st.dataframe(cases_done, use_container_width=True)

# -----------------------------
# EXPORT
# -----------------------------
with tabs[3]:
    st.header("Export Evaluations")

    if st.session_state.eval_df.empty:
        st.info("No evaluations to export yet.")
    else:
        # Excel export
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            st.session_state.eval_df.to_excel(writer, index=False, sheet_name="Evaluations")
        output.seek(0)

        st.download_button(
            label="Download evaluations as Excel file",
            data=output,
            file_name=f"khcc_evaluations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

        st.success("You can now share this file with the thesis team / analysts.")
